{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BLJ7pHax2IAT"
   },
   "source": [
    "## Variational Auto  Encoders\n",
    "\n",
    "- Reference: Adapted from the Keras example\n",
    "- Auto-Encoding Variational Bayes\n",
    "   https://arxiv.org/abs/1312.6114"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cPQHcmsL2IAX",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.backend.set_floatx('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y1_aCyYE2IAe",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, Flatten, Reshape, Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Th2ht-32IAk"
   },
   "source": [
    "## Fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OYvI_T2w2IAl",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "Xd30KcHc2IAp",
    "outputId": "289de4fd-3773-40a1-e79b-0fb2b48e045e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "for i in range(0, 18):\n",
    "    plt.subplot(3, 6, i + 1)\n",
    "    plt.imshow(x_train[i], cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "ToK41nu02IAv",
    "outputId": "6ecd25f9-6263-45d4-8c8d-0a04d45f7963",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZZe1OOY82IA1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NA3IgzNv2IA6"
   },
   "source": [
    "## Standard full-connected VAE model\n",
    "\n",
    "Let's define a VAE model with fully connected MLPs for the encoder and decoder networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "rP1GuwES2IA8",
    "outputId": "5cb6b84e-7d90-4f1d-e47c-a2b21ae7d957",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_standard = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test_standard = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "x_train_standard.shape, x_test_standard.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "my8-yfmE2IBA"
   },
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jUlCs2iv2IBB",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "original_dim = 784\n",
    "latent_dim = 2\n",
    "intermediate_dim = 256\n",
    "\n",
    "\n",
    "def make_encoder(original_dim, intermediate_dim, latent_dim):\n",
    "    x = Input(shape=(original_dim,))\n",
    "    hidden = Dense(intermediate_dim, activation='relu')(x)\n",
    "    z_mean = Dense(latent_dim)(hidden)\n",
    "    z_log_var = Dense(latent_dim)(hidden)\n",
    "    return Model(inputs=x, outputs=[z_mean, z_log_var],\n",
    "                name=\"mlp_encoder\")\n",
    "\n",
    "    \n",
    "encoder = make_encoder(original_dim, intermediate_dim, latent_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3D-Iwu72IBG"
   },
   "source": [
    "### The VAE stochastic latent variable\n",
    "\n",
    "We use the reparametrization trick to define a random variable z that is conditioned on the input image x as follows:\n",
    "\n",
    "$$ z \\sim \\mathcal{N}(\\mu_z(x), \\sigma_z(x)) $$\n",
    "\n",
    "The reparametrization tricks defines $z$ has follows:\n",
    "\n",
    "$$ z = \\mu_z(x) + \\sigma_z(x) \\cdot \\epsilon$$\n",
    "\n",
    "with:\n",
    "\n",
    "$$ \\epsilon \\sim \\mathcal{N}(0, 1) $$\n",
    "\n",
    "This way the dependency to between $z$ and $x$ is deterministic and differentiable. The randomness of $z$ only stems from $\\epsilon$ only for a given $x$.\n",
    "\n",
    "Note that in practice the output of the encoder network parameterizes $log(\\sigma^2_z(x)$ instead of $\\sigma_z(x)$. Taking the exponential of $log(\\sigma^2_z(x))$ ensures the positivity of the standard deviation from the raw output of the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OPEG8SW22IBH",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sampling_func(inputs):\n",
    "    z_mean, z_log_var = inputs\n",
    "    batch_size = tf.shape(z_mean)[0]\n",
    "    epsilon = tf.random.normal(shape=(batch_size, latent_dim),\n",
    "                              mean=0., stddev=1.)\n",
    "    return z_mean + tf.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "\n",
    "sampling_layer = Lambda(sampling_func, output_shape=(latent_dim,),\n",
    "                        name=\"latent_sampler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V905czPo2IBL"
   },
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g_jEeBl72IBM",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_decoder(latent_dim, intermediate_dim, original_dim):\n",
    "    decoder_input = Input(shape=(latent_dim,))\n",
    "    x = Dense(intermediate_dim, activation='relu')(decoder_input)\n",
    "    x = Dense(original_dim, activation='sigmoid')(x)\n",
    "    return Model(decoder_input, x, name=\"mlp_decoder\")\n",
    "\n",
    "\n",
    "decoder = make_decoder(latent_dim, intermediate_dim, original_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcHuir892IBP"
   },
   "source": [
    "By default the decoder outputs has random weights and output noise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "iMBcQjkr2IBP",
    "outputId": "e73fa356-cbd1-4e91-c5da-9ce5b7967620",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_z_from_prior = np.random.normal(loc=0, scale=1, size=(1, latent_dim))\n",
    "generated = decoder.predict(random_z_from_prior)\n",
    "plt.imshow(generated.reshape(28, 28), cmap=plt.cm.gray)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_bvQMHS2IBT"
   },
   "source": [
    "The generated image is completely univariate noise: there is no apparent spatial depenedencies between the pixel values. This reflects the lack of prior structure in the randomly initialized fully-connected decoder network. \n",
    "\n",
    "\n",
    "Let's now the plug the encoder and decoder via the stochastic latent variable $z$ to get the full VAE architecture. The loss function is the negative ELBO of the variational inference problem:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUM14atOr-6L"
   },
   "source": [
    "$$ \\underbrace{- \\mathbb{E}_{z \\sim q_\\phi(z|x)}\\left[ \\mathop{log} p_\\theta(x|z) \\right]}_{\\text{Reconstruction term}} + \\underbrace{D_{\\mathrm{KL}}\\left[q_\\phi(z|x) \\Vert p(z)\\right]}_{\\text{Regularization KL term}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mN40C6TzyAOo"
   },
   "source": [
    "Hint: The KL-divergence between two gaussians $\\mathcal{N}(\\mu_1, \\sigma_1)$ and $\\mathcal{N}(\\mu_2,\\sigma_2)$ is\n",
    "\n",
    "$$ D_{\\mathrm{KL}}\\left[p\\Vert q\\right] = \\log \\frac{\\sigma_2}{\\sigma_1} + \\frac{\\sigma_1^2 + (\\mu_1 - \\mu_2)^2}{2 \\sigma_2^2} - \\frac{1}{2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4XZg0k121sVn"
   },
   "source": [
    "*Exercice* Write the regularization_kl_term\n",
    "\n",
    "*Answer* Using the above equation and $\\mu_2=0$, $\\sigma_2=1$, we get\n",
    "\n",
    "$$ -\\frac12 \\left( 1 + \\mathop{log}(\\sigma^2) - \\sigma^2 - \\mu^2 \\right) \\;\\;. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7yPF_42e2IBU",
    "outputId": "48288217-4f2b-4a41-c5dc-c5027d5943af",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Exercise :\n",
    "# * Assemble the VAE using the sampling layer and the loss seen in class\n",
    "\n",
    "def make_vae(input_shape, encoder, decoder, sampling_layer):\n",
    "    # Build de model architecture by assembling the encoder,\n",
    "    # stochastic latent variable and decoder:\n",
    "    \n",
    "    ####\n",
    "    x = Input(shape=input_shape, name=\"input\")\n",
    "    z_mean, z_log_var = encoder(x)\n",
    "    z = sampling_layer([z_mean, z_log_var])\n",
    "    x_decoded_mean = decoder(z)\n",
    "    vae = Model(x, x_decoded_mean)\n",
    "\n",
    "    # Define the VAE loss\n",
    "    reconstruction_term = original_dim * metrics.binary_crossentropy(\n",
    "        Flatten()(x), Flatten()(x_decoded_mean))\n",
    "    \n",
    "    regularization_kl_term = - 0.5 * tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1)\n",
    "    vae_loss = tf.reduce_mean(reconstruction_term + regularization_kl_term)\n",
    "    ####\n",
    "\n",
    "    vae.add_loss(vae_loss)\n",
    "    vae.compile(optimizer='adam')\n",
    "    return vae\n",
    "\n",
    "vae = make_vae((original_dim,), encoder, decoder,\n",
    "               sampling_layer=sampling_layer)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "rOxPV_zy2IBW",
    "outputId": "9934ce51-c074-4290-b4ce-3306d07642e6",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vae.fit(x_train_standard, epochs=50, batch_size=100,\n",
    "        validation_data=(x_test_standard, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9iiFmCP2IBa"
   },
   "source": [
    "Note that the model has not yet converged even after 50 epochs. Furthermore it's is not overfitting significantly either. We chose a very low value for the latent dimension. It is likely that using the higher dimensional space could lead to a model either to optimize that would better fit the training set.\n",
    "\n",
    "By sampling a random latent vector from the prior distribution and feeding it to the decoder we can effectively sample from the image model trained by the VAE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "fVmhpa6X2IBb",
    "outputId": "cb187a39-da29-4089-f79a-476f5842953c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_z_from_prior = np.random.normal(size=(1, latent_dim)).astype(\"float32\")\n",
    "generated = decoder(random_z_from_prior).numpy()\n",
    "plt.imshow(generated.reshape(28, 28), cmap=plt.cm.gray)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mp_DgJH02IBe"
   },
   "source": [
    "Run the cell several times to sample from various random locations in the 2D latent space.\n",
    "\n",
    "The generated pictures are blurry but capture of the global organization of pixels required to represent samples from the 10 fashion item categories. The spatial structure has been learned and is only present in the decoder weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6UDjaRu2IBf"
   },
   "source": [
    "### 2D plot of the image classes in the latent space\n",
    "\n",
    "We can also use the encoder to set the visualize the distribution of the test set in the 2D latent space of the VAE model. In the following the colors show the true class labels from the test samples.\n",
    "\n",
    "Note that the VAE is an unsupervised model: it did not use any label information during training. However we can observe that the 2D latent space is largely structured around the categories of images used in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97eewgRy2IBg",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "id_to_labels = {0: \"T-shirt/top\", 1: \"Trouser\", 2: \"Pullover\", 3: \"Dress\", 4: \"Coat\", \n",
    "                5: \"Sandal\", 6: \"Shirt\", 7: \"Sneaker\", 8: \"Bag\", 9: \"Ankle boot\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 378
    },
    "id": "rhqj2S-w2IBj",
    "outputId": "31b2b891-5725-4b57-cc5f-a79aebe4eea3",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_test_encoded, _ = encoder(x_test_standard)\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test,\n",
    "            cmap=plt.cm.tab10)\n",
    "cb = plt.colorbar()\n",
    "cb.set_ticks(list(id_to_labels.keys()))\n",
    "cb.set_ticklabels(list(id_to_labels.values()))\n",
    "cb.update_ticks()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cLPxxvt92IBl"
   },
   "source": [
    "One can observe that the global 2D shape of the encoded dataset is approximately spherical with values with a maximum radius of size 3. Where can you explain where the shape of this marginal latent distribution come from?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tN3O55D_2IBm"
   },
   "source": [
    "### 2D panel view of samples from the VAE manifold\n",
    "\n",
    "The following linearly spaced coordinates on the unit square were transformed through the inverse CDF (ppf) of the Gaussian to produce values of the latent variables z. This makes it possible to use a square arangement of panels that spans the gaussian prior of the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "id": "RzWksFOY2IBn",
    "outputId": "7aa9333c-8b12-4f84-c58f-8147e0ce1652",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n = 15  # figure with 15x15 panels\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([[xi, yi]])\n",
    "        x_decoded = decoder(z_sample).numpy()\n",
    "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure, cmap='Greys_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1ftDhTb2IBq"
   },
   "source": [
    "## Convolutional Variational Auto Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "IjQFALhD2IBr",
    "outputId": "b231cbc5-9ce8-49c2-e84f-ab4cebae3d8f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_conv = np.expand_dims(x_train, -1)\n",
    "x_test_conv = np.expand_dims(x_test, -1)\n",
    "x_train_conv.shape, x_test_conv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5doC-L902IBu"
   },
   "source": [
    "**Exercise**: write an encoder that uses a series of convolutional layers, with maxpooling or strided convolutions and Batch norm to encode the 2D, gray-level images into 2D latent vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "id": "DGHjIw242IBv",
    "outputId": "f67fc342-e8a5-4c23-e73b-c85833763611",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "img_rows, img_cols, img_chns = 28, 28, 1\n",
    "filters = 32\n",
    "kernel_size = 3\n",
    "intermediate_dim = 128\n",
    "latent_dim = 2\n",
    "\n",
    "\n",
    "def make_conv_encoder(img_rows, img_cols, img_chns,\n",
    "                      latent_dim, intermediate_dim):\n",
    "    inp = Input(shape=(img_rows, img_cols, img_chns))\n",
    "    x = Conv2D(\n",
    "        filters=filters,\n",
    "        kernel_size=(kernel_size, kernel_size),\n",
    "        padding='same',\n",
    "        activation='relu',\n",
    "        strides=(2,2)\n",
    "    )(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(\n",
    "        filters=filters,\n",
    "        kernel_size=(kernel_size, kernel_size),\n",
    "        padding='same',\n",
    "        activation='relu',\n",
    "        strides=(2,2)\n",
    "    )(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(units=intermediate_dim, activation='relu')(x)\n",
    "\n",
    "    z_mean = Dense(latent_dim)(x)\n",
    "    z_log_var = Dense(latent_dim)(x)\n",
    "\n",
    "    return Model(inputs=inp, outputs=[z_mean, z_log_var],\n",
    "                 name='convolutional_encoder')\n",
    "\n",
    "\n",
    "conv_encoder = make_conv_encoder(img_rows, img_cols, img_chns,\n",
    "                                 latent_dim, intermediate_dim)\n",
    "print(conv_encoder.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "juzJi9RI2IB0"
   },
   "source": [
    "The stochastic latent variable is the same as for the fully-connected model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xdwSvH6-2IB1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sampling_layer = Lambda(sampling_func, output_shape=(latent_dim,),\n",
    "                        name=\"latent_sampler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_mSPjgb22IB5"
   },
   "source": [
    "## Decoder\n",
    "\n",
    "The decoder is also convolutional but instead of downsampling the spatial dimensions from (28, 28) to 2 latent dimensions, it starts from the latent space to upsample a (28, 28) dimensions using strided `Conv2DTranspose` layers.\n",
    "\n",
    "Here again BatchNormalization layers are inserted after the convolution to make optimization converge faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "id": "JJwK7Sot2IB7",
    "outputId": "de489203-1ca5-4509-be26-d28ac2b600a9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_conv_decoder(latent_dim, intermediate_dim, original_dim,\n",
    "                      spatial_size=7, filters=16):\n",
    "    decoder_input = Input(shape=(latent_dim,))\n",
    "    x = Dense(intermediate_dim, activation='relu')(decoder_input)\n",
    "    x = Dense(filters * spatial_size * spatial_size, activation='relu')(x)\n",
    "    x = Reshape((spatial_size, spatial_size, filters))(x)\n",
    "    # First up-sampling:\n",
    "    x = Conv2DTranspose(filters,\n",
    "                        kernel_size=3,\n",
    "                        padding='same',\n",
    "                        strides=(2, 2),\n",
    "                        activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2DTranspose(filters,\n",
    "                        kernel_size=3,\n",
    "                        padding='same',\n",
    "                        strides=1,\n",
    "                        activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # Second up-sampling:\n",
    "    x = Conv2DTranspose(filters,\n",
    "                        kernel_size=3,\n",
    "                        strides=(2, 2),\n",
    "                        padding='valid',\n",
    "                        activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    # Ouput 1 channel of gray pixels values between 0 and 1:\n",
    "    x = Conv2D(1, kernel_size=2, padding='valid',\n",
    "               activation='sigmoid')(x)\n",
    "    return Model(decoder_input, x, name='convolutional_decoder')\n",
    "\n",
    "\n",
    "conv_decoder = make_conv_decoder(latent_dim, intermediate_dim, original_dim,\n",
    "                                 spatial_size=7, filters=filters)\n",
    "print(conv_decoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "oqrOpFqP2IB9",
    "outputId": "f427b94f-5f4d-48be-b45b-0dc3d0bfe663",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generated = conv_decoder.predict(np.random.normal(size=(1, latent_dim)))\n",
    "plt.imshow(generated.reshape(28, 28), cmap=plt.cm.gray)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L1-ZeiZm2ICB"
   },
   "source": [
    "This new decoder encodes some a priori knowledge on the local dependencies between pixel values in the \"deconv\" architectures. Depending on the randomly initialized weights, the generated images can show some local spatial structure.\n",
    "\n",
    "Try to re-execute the above two cells several times to try to see the kind of local structure that stem from the \"deconv\" architecture it-self for different random initializations of the weights.\n",
    "\n",
    "\n",
    "Again, let's now plug everything to together to get convolutional version of a full VAE model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "I7DiOf0p2ICF",
    "outputId": "daa88b6f-813b-489c-f410-51423e0b7bb1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_shape = (img_rows, img_cols, img_chns)\n",
    "vae = make_vae(input_shape, conv_encoder, conv_decoder,\n",
    "               sampling_layer)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "id": "VnPB1xIW2ICI",
    "outputId": "7f9ec02e-3cd1-46b2-b054-211e838142df",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vae.fit(x_train_conv, epochs=15, batch_size=100,\n",
    "        validation_data=(x_test_conv, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "iMhJh8x72ICR",
    "outputId": "8861f27b-2026-44fb-c627-27f4f4f70d1c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generated = conv_decoder.predict(np.random.normal(size=(1, latent_dim)))\n",
    "plt.imshow(generated.reshape(28, 28), cmap=plt.cm.gray)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bGfRpLzf2ICV"
   },
   "source": [
    "### 2D plot of the image classes in the latent space\n",
    "\n",
    "We find again a similar organization of the latent space. Compared to the fully-connected VAE space, the differnt class labels seem slightly better separated. This could be a consequence of the slightly better fit we obtain from the convolutional models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 378
    },
    "id": "thiO0kgF2ICW",
    "outputId": "b69993db-7bdd-4685-fbfd-94bcb87d9f5a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_test_encoded, _ = conv_encoder(x_test_conv)\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test,\n",
    "            cmap=plt.cm.tab10)\n",
    "cb = plt.colorbar()\n",
    "cb.set_ticks(list(id_to_labels.keys()))\n",
    "cb.set_ticklabels(list(id_to_labels.values()))\n",
    "cb.update_ticks()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MEP0O-jf2ICZ"
   },
   "source": [
    "### 2D panel view of samples from the VAE manifold\n",
    "\n",
    "The following linearly spaced coordinates on the unit square were transformed through the inverse CDF (ppf) of the Gaussian to produce values of the latent variables z. This makes it possible to use a square arangement of panels that spans the gaussian prior of the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IhOSpbPn2ICZ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = 15  # figure with 15x15 panels\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([[xi, yi]])\n",
    "        x_decoded = conv_decoder.predict(z_sample)\n",
    "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure, cmap='Greys_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xR_xS4EJga5v"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "bGfRpLzf2ICV",
    "MEP0O-jf2ICZ",
    "K08zT-7U2ICc",
    "nlf0DoSx2ICz"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
